{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation des images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Créer un dataset personnalisé\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, labels, transform=None):\n",
    "        self.root = root\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.root, self.labels.iloc[idx]['Path'])\n",
    "        image = Image.open(img_path).convert('RGB')  # Ouvrir l'image et la convertir en RGB\n",
    "        label = self.labels.iloc[idx]['ClassId']  # Récupérer l'étiquette\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # Appliquer les transformations (si présentes)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=8):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle et optimiseur chargés avec succès depuis ./model_resnet4_classes.pth et ./optimizer_resnet4_classes.pth\n"
     ]
    }
   ],
   "source": [
    "# Chemins des fichiers sauvegardés\n",
    "MODEL_PATH = './model_resnet4_classes.pth'\n",
    "OPTIMIZER_PATH = './optimizer_resnet4_classes.pth'\n",
    "\n",
    "# Définir l'appareil (CPU ou GPU)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instancier le modèle avec la même architecture\n",
    "model = ResNet(BasicBlock, layers=[3, 4, 6, 3], num_classes=8)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Instancier l'optimiseur avec les mêmes paramètres\n",
    "optimizer = torch.optim.SGD(model.parameters(), momentum=0.9, lr=0.01)\n",
    "optimizer.load_state_dict(torch.load(OPTIMIZER_PATH, map_location=DEVICE))\n",
    "\n",
    "print(f\"Modèle et optimiseur chargés avec succès depuis {MODEL_PATH} et {OPTIMIZER_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe prédite : 1 - Vitesse associée : Stop\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Mode évaluation (désactive le dropout, batchnorm)\n",
    "model.eval()\n",
    "\n",
    "# Exemple d'utilisation pour une image de test\n",
    "test_image_path = './archive/Test/00014_00022_00022.png'\n",
    "test_image = Image.open(test_image_path).convert('RGB')\n",
    "\n",
    "# Appliquer les transformations\n",
    "test_image = transform(test_image).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "# Effectuer la prédiction\n",
    "with torch.no_grad():  # Désactive le calcul de gradients pour l'inférence\n",
    "    output = model(test_image)\n",
    "    _, predicted_class = torch.max(output, 1)\n",
    "\n",
    "# Dictionnaire des correspondances classe -> vitesse\n",
    "speed_limits = {\n",
    "    0: \"30 km/h\",\n",
    "    1: \"Stop\",\n",
    "    2: \"50 km/h\",\n",
    "    3: \"70 km/h\",\n",
    "    4: \"80 km/h\",\n",
    "    6: \"110 km/h\",\n",
    "    5: \"90 km/h\" ,\n",
    "    7: \"130mn/h\"\n",
    "\n",
    "}\n",
    "\n",
    "# Récupérer la vitesse correspondante\n",
    "predicted_speed = speed_limits.get(predicted_class.item(), \"Classe inconnue\")\n",
    "\n",
    "print(f'Classe prédite : {predicted_class.item()} - Vitesse associée : {predicted_speed}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
